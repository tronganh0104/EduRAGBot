{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6207f5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\LLM\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\miniconda3\\envs\\LLM\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import faiss\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from rank_bm25 import BM25Okapi\n",
    "from underthesea import word_tokenize\n",
    "from langchain_core.documents import Document\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d1dd9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     from langchain_cohere import CohereRerank\n",
    "#     COHERE_AVAILABLE = True\n",
    "# except ImportError:    \n",
    "#     COHERE_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584164ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"index_path\": \"../index.faiss\",\n",
    "    \"docs_path\": \"../docs.pkl\",\n",
    "    \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"reranker_model\": \"BAAI/bge-reranker-base\",\n",
    "    \"default_dense_k\": 10,\n",
    "    \"default_bm25_k\": 10,\n",
    "    \"default_top_n\": 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fabc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionClassifier:\n",
    "    def __init__(self, model_path=\"models/question_classifier\"):\n",
    "        print(f\"Đang tải mô hình phân loại từ: {model_path}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        self.id2label = self.model.config.id2label\n",
    "\n",
    "    def classify(self, question: str) -> str:\n",
    "        inputs = self.tokenizer(\n",
    "            question, \n",
    "            return_tensors=\"pt\", \n",
    "            truncation=True, \n",
    "            padding=True,\n",
    "            max_length=128\n",
    "        ).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        \n",
    "        prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "        return self.id2label[prediction]\n",
    "\n",
    "class AdvancedQuerySystem:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.classifier = QuestionClassifier()\n",
    "        print(\"Đang khởi tạo retrieval\")\n",
    "        self.embedding_model = SentenceTransformer(self.config['embedding_model'])\n",
    "        self.reranker = CrossEncoder(self.config['reranker_model'])\n",
    "        self.index = faiss.read_index(self.config['index_path'])\n",
    "        with open(self.config['docs_path'], \"rb\") as f:\n",
    "            self.docs = pickle.load(f)\n",
    "        self.corpus = [doc['content'] for doc in self.docs]\n",
    "        tokenized_corpus = [word_tokenize(doc) for doc in self.corpus]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "        self.content_to_doc_map = {doc['content']: doc for doc in self.docs}\n",
    "        print(\"Ready\")\n",
    "        \n",
    "    def _dense_retrieval(self, question: str, k: int) -> list:\n",
    "        query_vector = self.embedding_model.encode(question)\n",
    "        query_vector_2d = np.array([query_vector], dtype='float32')\n",
    "        distances, indices = self.index.search(query_vector_2d, k=k)\n",
    "        return [self.docs[i] for i in indices[0]]\n",
    "\n",
    "    def _bm25_retrieval(self, question: str, k: int) -> list:\n",
    "        tokenized_query = word_tokenize(question)\n",
    "        top_k_contents = self.bm25.get_top_n(tokenized_query, self.corpus, n=k)\n",
    "        return [self.content_to_doc_map[content] for content in top_k_contents]\n",
    "\n",
    "    def _rerank(self, question: str, candidate_docs: list[Document], top_n: int) -> list[Document]:        \n",
    "        reranker_input = [[question, doc.page_content] for doc in candidate_docs]\n",
    "        scores = self.reranker.predict(reranker_input)\n",
    "        doc_score_pairs = list(zip(candidate_docs, scores))\n",
    "        doc_score_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "        reranked_docs = [doc for doc, score in doc_score_pairs[:top_n]]\n",
    "        return reranked_docs\n",
    "\n",
    "    def query(self, question: str) -> list[Document]:                \n",
    "        question_type = self.classifier.classify(question)\n",
    "        print(idx)\n",
    "        print(f\"Loại câu hỏi được xác định: {question_type}\")\n",
    "        \n",
    "        # Chiến lược truy vấn\n",
    "        dense_k = self.config['default_dense_k']\n",
    "        bm25_k = self.config['default_bm25_k']\n",
    "        top_n = self.config['default_top_n']\n",
    "\n",
    "        if question_type == \"Definition\" or question_type == \"Factoid\":            \n",
    "            dense_k = 8\n",
    "            bm25_k = 12 # Ưu tiên BM25\n",
    "            top_n = 1    # Chỉ cần 1 chunk là đủ\n",
    "        elif question_type == \"List\":            \n",
    "            dense_k = 12\n",
    "            bm25_k = 12\n",
    "            top_n = 5    # Lấy nhiều chunk hơn chút vì cần list chunk ra                        \n",
    "        elif question_type == \"Inference\":            \n",
    "            dense_k = 15 # Tăng mạnh k để suy luận tốt hơn\n",
    "            bm25_k = 15\n",
    "            top_n = 5    \n",
    "        # Loại Y/N thì để tham số mặc định\n",
    "\n",
    "        # HYBRID SEARCH        \n",
    "        dense_results = self._dense_retrieval(question, k=dense_k)\n",
    "        bm25_results = self._bm25_retrieval(question, k=bm25_k)\n",
    "        \n",
    "        all_results_dict = {doc_data['content']: doc_data for doc_data in dense_results + bm25_results}\n",
    "        candidate_docs_data = list(all_results_dict.values())\n",
    "        \n",
    "        candidate_docs_lc = [\n",
    "            Document(page_content=doc['content'], metadata=doc['metadata']) \n",
    "            for doc in candidate_docs_data\n",
    "        ]        \n",
    "\n",
    "        # RERANKING\n",
    "        final_docs = self._rerank(question, candidate_docs_lc, top_n)\n",
    "        \n",
    "        return final_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d79d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tải mô hình phân loại từ: models/question_classifier\n",
      "Đang khởi tạo retrieval\n",
      "Ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\LLM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Loại câu hỏi được xác định: Definition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\LLM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\LLM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "Kết quả cuối cùng cho câu hỏi 'Học phần điều kiện là gì ?' (Loại được test: Definition):\n",
      "  --- Document 1 ---\n",
      "  Nội dung: 1. Học phân là một phần kiến thức của chương trình đảo tạo; mỗi học phần\n",
      "có khối lượng kiến thức từ 2 đến 5 tín chỉ, được tổ chức giảng dạy trọn vẹn trong\n",
      "một học kỳ (trừ học phân thực tập thực tế); mỗi học phần có mã số riêng do thủ\n",
      "trưởng đơn vị đào tạo ban hành dựa trên nguyên tắc đánh mã của Đại học Quốc gia\n",
      "Hà Nội.\n",
      "\f2. Các loại học phần\n",
      "a) Học...\n",
      "2\n",
      "Loại câu hỏi được xác định: Yes/No\n",
      "2\n",
      "\n",
      "Kết quả cuối cùng cho câu hỏi 'Sinh viên có được phép học cùng lúc hai chương trình không?' (Loại được test: Yes/No):\n",
      "  --- Document 1 ---\n",
      "  Nội dung: 1. Sinh viên đang học tại các đơn vị đào tạo của Đại học Quốc gia Hà Nội\n",
      "theo hình thức đào tạo chính quy được đăng ký học thêm một chương trình đào tạo\n",
      "thứ hai nêu có đủ các điêu kiện:\n",
      "a) Ngành học chính của chương trình đào tạo thứ hai phải khác ngành học\n",
      "chính của chương trình đào tạo thứ nhất;\n",
      "b) Đã học ít nhât hai học kỳ của chương trình đào t...\n",
      "  --- Document 2 ---\n",
      "  Nội dung: I. Đề tính điểm trung bình chung học kỳ, điểm trung bình chung các học\n",
      "phần và điểm trung bình chung tích lũy, mức điêm chữ của mỗi học phân được quy\n",
      "đôi thành điểm sô như sau:\n",
      "\f45\n",
      "A' tương ứng với 4,0\n",
      "A tương ứng với lu?\n",
      "B' tương ứng với 3.5\n",
      "B tương ứng với KT É\n",
      "\"hà tương ứng với BÁC\n",
      "C tương ứng với 2,0\n",
      "D' tương ứng với 1,5\n",
      "D tương ứng với 1,0\n",
      "F t...\n",
      "  --- Document 3 ---\n",
      "  Nội dung: 1. Định kỳ mỗi năm 4 lần (tháng 3, tháng 6 và tháng 7, tháng 9, tháng 12),\n",
      "thủ trưởng đơn vị đào tạo ra quyết định thành lập Hội đồng xét tốt nghiệp cho sinh\n",
      "viên đã hoàn thành chương trình đảo tạo của đơn vị. Hội đồng xét tốt nghiệp do\n",
      "thủ trưởng hoặc cắp phó của thủ trưởng đơn vị đào tạo làm Chủ tịch, đại diện lãnh\n",
      "đạo Phòng Đảo tạo làm ủy viên t...\n",
      "3\n",
      "Loại câu hỏi được xác định: List\n",
      "3\n",
      "\n",
      "Kết quả cuối cùng cho câu hỏi 'Liệt kê các hạng tốt nghiệp của sinh viên?' (Loại được test: List):\n",
      "  --- Document 1 ---\n",
      "  Nội dung: I. Đề tính điểm trung bình chung học kỳ, điểm trung bình chung các học\n",
      "phần và điểm trung bình chung tích lũy, mức điêm chữ của mỗi học phân được quy\n",
      "đôi thành điểm sô như sau:\n",
      "\f45\n",
      "A' tương ứng với 4,0\n",
      "A tương ứng với lu?\n",
      "B' tương ứng với 3.5\n",
      "B tương ứng với KT É\n",
      "\"hà tương ứng với BÁC\n",
      "C tương ứng với 2,0\n",
      "D' tương ứng với 1,5\n",
      "D tương ứng với 1,0\n",
      "F t...\n",
      "  --- Document 2 ---\n",
      "  Nội dung: 1. Định kỳ mỗi năm 4 lần (tháng 3, tháng 6 và tháng 7, tháng 9, tháng 12),\n",
      "thủ trưởng đơn vị đào tạo ra quyết định thành lập Hội đồng xét tốt nghiệp cho sinh\n",
      "viên đã hoàn thành chương trình đảo tạo của đơn vị. Hội đồng xét tốt nghiệp do\n",
      "thủ trưởng hoặc cắp phó của thủ trưởng đơn vị đào tạo làm Chủ tịch, đại diện lãnh\n",
      "đạo Phòng Đảo tạo làm ủy viên t...\n",
      "  --- Document 3 ---\n",
      "  Nội dung: 1. Học phân là một phần kiến thức của chương trình đảo tạo; mỗi học phần\n",
      "có khối lượng kiến thức từ 2 đến 5 tín chỉ, được tổ chức giảng dạy trọn vẹn trong\n",
      "một học kỳ (trừ học phân thực tập thực tế); mỗi học phần có mã số riêng do thủ\n",
      "trưởng đơn vị đào tạo ban hành dựa trên nguyên tắc đánh mã của Đại học Quốc gia\n",
      "Hà Nội.\n",
      "\f2. Các loại học phần\n",
      "a) Học...\n",
      "  --- Document 4 ---\n",
      "  Nội dung: Các học phần có cùng nội dung, thời lượng mà sinh viên chuyển trường\n",
      "trong và ngoài Đại học Quốc gia Hà Nội, học liên thông (nếu có), học cùng lúc hai\n",
      "chương trình đào tạo, học tại trường đại học nước ngoài đã tích lũy được xem xét\n",
      "công nhận. Các học phần khác, căn cứ chương trình đảo tạo và nội dung đào tạo,\n",
      "thủ trưởng đơn vị đảo tạo quyết định bả...\n",
      "  --- Document 5 ---\n",
      "  Nội dung: I. Được hưởng dầy đủ chế độ, chính sách hiện hành của Đảng, Nhà nước\n",
      "cũng như các quy chế, quy định của Đại học Quốc gia Hà Nội và của đơn vị đào tạo.\n",
      "2. Được phép thôi học vì lý do chủ quan của cá nhân, trong trường hợp này,\n",
      "sinh viên phải hoàn trả cho đơn vị đào tạo toàn bộ kinh phí đào tạo từ ngân sách\n",
      "nhà nước trong thời gian theo học.\n",
      "\f37\n",
      "3. S...\n",
      "4\n",
      "Loại câu hỏi được xác định: Inference\n",
      "4\n",
      "\n",
      "Kết quả cuối cùng cho câu hỏi 'Làm thế nào để một sinh viên đang học chương trình chuẩn có thể chuyển sang học chương trình tài năng?' (Loại được test: Inference):\n",
      "  --- Document 1 ---\n",
      "  Nội dung: 1. Điểm đánh giá bộ phận và điểm thi kết thúc học phần được chấm theo\n",
      "thang điểm 10 (từ 0 đến 10), có lẻ đến một chữ số thập phân.\n",
      "2. Điểm học phần là tổng của điểm đánh giá bộ phận và điểm thi kết thúc\n",
      "học phần sau khi đã tính trọng số được quy định trong đề cương học phần và được\n",
      "làm tròn đến một chữ só thập phân, sau đó được chuyên thành điểm ch...\n",
      "  --- Document 2 ---\n",
      "  Nội dung: I. Được hưởng dầy đủ chế độ, chính sách hiện hành của Đảng, Nhà nước\n",
      "cũng như các quy chế, quy định của Đại học Quốc gia Hà Nội và của đơn vị đào tạo.\n",
      "2. Được phép thôi học vì lý do chủ quan của cá nhân, trong trường hợp này,\n",
      "sinh viên phải hoàn trả cho đơn vị đào tạo toàn bộ kinh phí đào tạo từ ngân sách\n",
      "nhà nước trong thời gian theo học.\n",
      "\f37\n",
      "3. S...\n",
      "  --- Document 3 ---\n",
      "  Nội dung: 1. Việc kiêm tra đánh giá và châm điểm bộ phận của mỗi học phần do giảng\n",
      "viên lớp học phân trực tiệp thực hiện và thông báo kết quả cho sinh viên, chậm\n",
      "nhất 7 ngày làm việc kề từ sau ngày kiểm tra hoặc ngày nộp tiểu luận, bài tập lớn.\n",
      "\f39\n",
      "Sinh viên chưa có điểm đánh giá bộ phận vì có lý do chính đáng được Chủ\n",
      "nhiệm Khoa/Bộ môn và giảng viên đồng ý ...\n",
      "  --- Document 4 ---\n",
      "  Nội dung: l. Nội dung đào tạo, phương pháp dạy - học, kiểm tra đánh giá và phương\n",
      "thức quản lý phải phù hợp và đáp ứng chuẩn đầu ra của chương trình đào tạo.\n",
      "2. Phát triển các chương trình đảo tạo mới, có tính liên ngành đáp ứng nhu\n",
      "cầu hiện tại và tương lai của xã hội.\n",
      "\f3. Ưu tiên đầu tư điều kiện đảm bảo chất lượng giáo dục.\n",
      "4. Gắn đào tạo với nghiên cứu k...\n",
      "  --- Document 5 ---\n",
      "  Nội dung: 1. Thủ trưởng đơn vị đào tạo quy định cụ thẻ về quy trình thực hiện bảo vệ\n",
      "và đánh giá khóa luận, đỗ án tốt nghiệp; quyết định thành lập Hội đông bảo vệ và\n",
      "đánh giá khoá luận hoặc đồ án tốt nghiệp gồm ít nhất 3 thành viên đo Chủ nhiệm\n",
      "khoa (đối với trường dại học thành viên) hoặc Chủ nhiệm bộ môn (đôi với\n",
      "Trường/Khoa trực thuộc) đê nghị; trong trườ...\n",
      "5\n",
      "Loại câu hỏi được xác định: Factoid\n",
      "5\n",
      "\n",
      "Kết quả cuối cùng cho câu hỏi 'Điểm chữ F tương ứng với thang điểm số mấy?' (Loại được test: Factoid):\n",
      "  --- Document 1 ---\n",
      "  Nội dung: 1. Điểm đánh giá bộ phận và điểm thi kết thúc học phần được chấm theo\n",
      "thang điểm 10 (từ 0 đến 10), có lẻ đến một chữ số thập phân.\n",
      "2. Điểm học phần là tổng của điểm đánh giá bộ phận và điểm thi kết thúc\n",
      "học phần sau khi đã tính trọng số được quy định trong đề cương học phần và được\n",
      "làm tròn đến một chữ só thập phân, sau đó được chuyên thành điểm ch...\n"
     ]
    }
   ],
   "source": [
    "if not (os.path.exists(CONFIG['index_path']) and os.path.exists(CONFIG['docs_path'])):\n",
    "        print(f\"LỖI: Không tìm thấy file tại '{CONFIG['index_path']}' hoặc '{CONFIG['docs_path']}'.\")\n",
    "else:    \n",
    "    query_system = AdvancedQuerySystem(CONFIG)\n",
    "    \n",
    "    test_queries = {\n",
    "        \"Definition\": \"Học phần điều kiện là gì ?\",\n",
    "        \"Yes/No\": \"Sinh viên có được phép học cùng lúc hai chương trình không?\",\n",
    "        \"List\": \"Liệt kê các hạng tốt nghiệp của sinh viên?\",\n",
    "        \"Inference\": \"Làm thế nào để một sinh viên đang học chương trình chuẩn có thể chuyển sang học chương trình tài năng?\",\n",
    "        \"Factoid\": \"Điểm chữ F tương ứng với thang điểm số mấy?\"\n",
    "    }\n",
    "    for q_type, q_text in test_queries.items():\n",
    "        final_results = query_system.query(q_text)                \n",
    "        print(f\"\\nKết quả cuối cùng cho câu hỏi '{q_text}' (Loại được test: {q_type}):\")\n",
    "        for i, doc in enumerate(final_results):\n",
    "            print(f\"  --- Document {i+1} ---\")\n",
    "            print(f\"  Nội dung: {doc.page_content[:350]}...\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1da1ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class QuerySystem:\n",
    "#     def __init__(self, config):\n",
    "#         self.config = config\n",
    "#         print(\"Đang khởi tạo\")            \n",
    "#         self.embedding_model = SentenceTransformer(self.config['embedding_model'])        \n",
    "#         self.reranker = self._load_reranker()\n",
    "\n",
    "#         self.index = faiss.read_index(self.config['index_path'])                \n",
    "#         with open(self.config['docs_path'], \"rb\") as f:\n",
    "#             self.docs = pickle.load(f)            \n",
    "\n",
    "#     def _load_reranker(self):\n",
    "#         cohere_api_key = os.environ.get(\"COHERE_API_KEY\")\n",
    "#         if COHERE_AVAILABLE and cohere_api_key:\n",
    "#             print(\"Có thể áp dụng Cohere Reranker.\")\n",
    "#             return CohereRerank(\n",
    "#                 cohere_api_key=cohere_api_key,\n",
    "#                 model=\"rerank-multilingual-v3.0\",\n",
    "#                 top_n=self.config[\"reranker_top_n\"]\n",
    "#             )\n",
    "#         else:\n",
    "#             print(f\"Không tìm thấy COHERE_API_KEY. Sử dụng CrossEncoder: {self.config['reranker_model']}\")\n",
    "#             return CrossEncoder(self.config['reranker_model'])\n",
    "\n",
    "#     def query(self, text: str) -> list[Document]:        \n",
    "#         query_vector = self.embedding_model.encode(text)\n",
    "#         query_vector_2d = np.array([query_vector], dtype='float32')\n",
    "                \n",
    "#         distances, indices = self.index.search(query_vector_2d, k=self.config[\"retriever_k\"])        \n",
    "#         retrieved_docs_data = [self.docs[i] for i in indices[0]]\n",
    "        \n",
    "#         retrieved_docs_lc = [\n",
    "#             Document(page_content=doc['content'], metadata=doc['metadata']) \n",
    "#             for doc in retrieved_docs_data\n",
    "#         ]\n",
    "        \n",
    "#         print(f\"\\nCÂU HỎI: '{text}'\")\n",
    "#         print(f\"Đã truy vấn được {len(retrieved_docs_lc)} tài liệu ban đầu.\")\n",
    "\n",
    "#         # ---RERANKING---\n",
    "#         if not self.reranker:\n",
    "#             print(\"Không có reranker, trả về kết quả truy vấn cơ bản.\")\n",
    "#             return retrieved_docs_lc\n",
    "\n",
    "#         print(\"Đang thực hiện Reranking...\")\n",
    "#         if isinstance(self.reranker, CohereRerank):\n",
    "#             reranked_docs = self.reranker.compress_documents(\n",
    "#                 documents=retrieved_docs_lc,\n",
    "#                 query=text\n",
    "#             )\n",
    "#         else: \n",
    "#             reranker_input = [[text, doc.page_content] for doc in retrieved_docs_lc]\n",
    "#             scores = self.reranker.predict(reranker_input)\n",
    "            \n",
    "#             doc_score_pairs = list(zip(retrieved_docs_lc, scores))\n",
    "#             doc_score_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "#             reranked_docs = [doc for doc, score in doc_score_pairs[:self.config[\"reranker_top_n\"]]]\n",
    "\n",
    "#         return reranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69709813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG = {\n",
    "#     \"index_path\": \"../vector_store_data_v2/index.faiss\",  \n",
    "#     \"docs_path\": \"../vector_store_data_v2/docs.pkl\",      \n",
    "#     \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "#     \"reranker_model\": \"BAAI/bge-reranker-base\",\n",
    "#     \"retriever_k\": 5,\n",
    "#     \"reranker_top_n\": 1\n",
    "# }\n",
    "\n",
    "# if not (os.path.exists(CONFIG['index_path']) and os.path.exists(CONFIG['docs_path'])):\n",
    "#     print(f\"LỖI: Không tìm thấy file tại '{CONFIG['index_path']}' hoặc '{CONFIG['docs_path']}'.\")\n",
    "# else:    \n",
    "#     query_system = QuerySystem(CONFIG)        \n",
    "#     user_query = \"Học phần điều kiện là gì ?\"    \n",
    "#     final_results = query_system.query(user_query)\n",
    "        \n",
    "#     print(f\"\\nKết quả cuối cùng sau khi Reranking (top {len(final_results)}):\")\n",
    "#     for i, doc in enumerate(final_results):\n",
    "#         print(f\"  ------------ Document {i+1} -------------\")\n",
    "#         print(f\"  Nội dung: {doc.page_content}\")        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
